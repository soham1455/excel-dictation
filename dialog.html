<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Dictation Dialog</title>
  <style>
    body{font-family:Arial;margin:14px}
    button{margin-right:8px;padding:8px 10px}
    #history{border:1px solid #ddd;padding:8px;min-height:120px;margin-top:10px;overflow:auto}
  </style>
</head>
<body>
  <h3>Dictation (Popup)</h3>
  <button id="startBtn">Start Dictation</button>
  <button id="stopBtn" disabled>Stop</button>
  <div id="status">Status: idle</div>
  <div id="history"></div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');
    const statusEl = document.getElementById('status');
    const historyEl = document.getElementById('history');

    function updateStatus(s){ statusEl.textContent = 'Status: ' + s; }
    function append(text){
      const d = document.createElement('div'); d.textContent = text; historyEl.prepend(d);
    }

    const SpeechRec = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRec) {
      updateStatus('Browser does not support SpeechRecognition. Use Chrome/Edge.');
      startBtn.disabled = true;
    } else {
      let recognition = new SpeechRec();
      recognition.interimResults = true;
      recognition.continuous = true;

      recognition.onstart = () => updateStatus('listening...');
      recognition.onend = () => { updateStatus('stopped'); startBtn.disabled=false; stopBtn.disabled=true; };
      recognition.onerror = (e) => updateStatus('error: ' + (e.error || e.message || e.name));

      recognition.onresult = (ev) => {
        let finalText = '';
        for (let i = ev.resultIndex; i < ev.results.length; i++) {
          if (ev.results[i].isFinal) finalText += ev.results[i][0].transcript;
        }
        if (finalText) {
          append(finalText);
          // send transcript back to parent (Office add-in)
          try {
            // In Office dialog we should use Office API if available:
            if (window.Office && Office.context && Office.context.ui && Office.context.ui.messageParent) {
              Office.context.ui.messageParent(finalText);
            } else if (window.opener && window.opener.postMessage) {
              // fallback: use postMessage to opener (if allowed)
              window.opener.postMessage({ type: 'dictation', text: finalText }, '*');
            }
          } catch (e) {
            console.warn('send transcript failed', e);
          }
        }
      };

      startBtn.addEventListener('click', async () => {
        try {
          await navigator.mediaDevices.getUserMedia({ audio: true });
          recognition.start();
          startBtn.disabled = true; stopBtn.disabled = false;
        } catch (err) {
          alert('Microphone access required. Please allow microphone permission for this popup.');
        }
      });

      stopBtn.addEventListener('click', ()=> { try { recognition.stop(); } catch(e){} });
    }
  </script>
</body>
</html>
